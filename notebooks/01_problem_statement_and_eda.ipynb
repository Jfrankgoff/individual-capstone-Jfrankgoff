{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Problem Statement & Exploratory Data Analysis\n",
    "\n",
    "**Student Name:** Jesse Goff\n",
    "\n",
    "**Dataset:** Material_Lifespan_Dataset.csv\n",
    "\n",
    "**Checkpoints:**\n",
    "- Checkpoint 1 (Due Feb 1): Sections 1-3\n",
    "- Checkpoint 2 (Due Feb 8): Sections 4-6\n",
    "\n",
    "---\n",
    "\n",
    "## Rules & Integrity\n",
    "\n",
    "1. **NO AI TOOLS**: You may **NOT** use ChatGPT, Claude, Gemini, GitHub Copilot, or any other AI assistant to generate code for this assignment. The goal is to build *your* fundamental skills. If you rely on AI now, the advanced topics later will be impossible.\n",
    "\n",
    "2. **Study Groups Encouraged**: You **ARE** encouraged to discuss ideas, share approaches, and explain concepts to your study group peers. Teaching others is the best way to learn! However, the code you submit must be **your own work**.\n",
    "\n",
    "3. **Use Your Resources**: You are free to use Google, StackOverflow, Pandas/Scikit-learn documentation, and your class notes.\n",
    "\n",
    "4. **Comment Your Code**: Include comments explaining *why* you're doing what you're doing. I want to see your thought process.\n",
    "\n",
    "5. **Resubmission**: You may submit this assignment multiple times for feedback before each checkpoint deadline.\n",
    "\n",
    "---\n",
    "\n",
    "## Important: Written Reflections\n",
    "\n",
    "Throughout this notebook, you'll see text cells asking you to explain your decisions, observations, and reasoning. **These written reflections are a critical part of your grade.** \n",
    "\n",
    "Don't just write one-word answers or skip these sections. Your reflections demonstrate:\n",
    "- Your understanding of the data science process\n",
    "- Your ability to communicate findings to stakeholders\n",
    "- Your critical thinking about data quality and feature importance\n",
    "\n",
    "Take time to write thoughtful, complete responses. This is what separates a good data scientist from someone who just runs code!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell first to import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CHECKPOINT 1 (Due: Feb 1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Problem Statement\n",
    "\n",
    "### 1.1 What are you trying to predict?\n",
    "\n",
    "*Clearly state your target variable and what it represents.*\n",
    "\n",
    "**Your answer:**\n",
    "\n",
    "The target variable that I want to predict is a calculated column called Defects. This will be a row-level calculation which is the sum of MinorDefects, MajorDefects, and EdgeDefects.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Why does this prediction matter?\n",
    "\n",
    "*Who would care about this prediction? What decisions could be made with it?*\n",
    "\n",
    "**Your answer:**\n",
    "\n",
    "There are several people that would care about this prediction - Plant Managers, Engineers, Shift Leads, Maintenance Teams, Regulatory/Compliance, Supplier Quality, Customer Quality, etc. Closer attention can be paid to components that are predicted to have a high amount of defects. Engineers can be tasked with designing components made of materials that are less likely to have defects. \n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 What features might help predict the target?\n",
    "\n",
    "*Based on your intuition and domain knowledge, what columns do you think will be most important?*\n",
    "\n",
    "**Your answer:**\n",
    "\n",
    "I suspect NickelComposition, IronComposition, CobaltComposition and ChromiumComposition will be the most meaningful features. Other features of interest are QuinchDuration, ForgeDuration and FormationMethod. I hypothesize ComponentType and StructureType will be less valuable but these should still be explored. Our analysis could reveal defect patterns that could be addressed for all of these features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Dataset Overview\n",
    "\n",
    "### 2.1 Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 1,000 rows, 16 columns\n",
      "\n",
      "Column names:\n",
      "['PredictedHours', 'ComponentType', 'StructureType', 'CoolRate', 'QuenchDuration', 'ForgeDuration', 'HeatProcessTime', 'NickelComposition', 'IronComposition', 'CobaltComposition', 'ChromiumComposition', 'MinorDefects', 'MajorDefects', 'EdgeDefects', 'InitialPosition', 'FormationMethod']\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "# Update the path to match your file name\n",
    "df = pd.read_csv('../data/raw/Material_Lifespan_Dataset.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictedHours</th>\n",
       "      <th>ComponentType</th>\n",
       "      <th>StructureType</th>\n",
       "      <th>CoolRate</th>\n",
       "      <th>QuenchDuration</th>\n",
       "      <th>ForgeDuration</th>\n",
       "      <th>HeatProcessTime</th>\n",
       "      <th>NickelComposition</th>\n",
       "      <th>IronComposition</th>\n",
       "      <th>CobaltComposition</th>\n",
       "      <th>ChromiumComposition</th>\n",
       "      <th>MinorDefects</th>\n",
       "      <th>MajorDefects</th>\n",
       "      <th>EdgeDefects</th>\n",
       "      <th>InitialPosition</th>\n",
       "      <th>FormationMethod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461.797</td>\n",
       "      <td>Nozzle</td>\n",
       "      <td>equiGrain</td>\n",
       "      <td>12.836</td>\n",
       "      <td>3.803</td>\n",
       "      <td>6.515</td>\n",
       "      <td>47.005</td>\n",
       "      <td>65.450</td>\n",
       "      <td>16.618</td>\n",
       "      <td>16.510</td>\n",
       "      <td>0.938</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1825.977</td>\n",
       "      <td>Block</td>\n",
       "      <td>singleGrain</td>\n",
       "      <td>19.032</td>\n",
       "      <td>2.593</td>\n",
       "      <td>3.521</td>\n",
       "      <td>45.246</td>\n",
       "      <td>54.162</td>\n",
       "      <td>34.916</td>\n",
       "      <td>6.063</td>\n",
       "      <td>4.292</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>707.101</td>\n",
       "      <td>Blade</td>\n",
       "      <td>equiGrain</td>\n",
       "      <td>28.418</td>\n",
       "      <td>0.772</td>\n",
       "      <td>1.327</td>\n",
       "      <td>9.639</td>\n",
       "      <td>52.565</td>\n",
       "      <td>36.486</td>\n",
       "      <td>8.927</td>\n",
       "      <td>3.355</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1086.370</td>\n",
       "      <td>Nozzle</td>\n",
       "      <td>colGrain</td>\n",
       "      <td>9.084</td>\n",
       "      <td>1.990</td>\n",
       "      <td>2.201</td>\n",
       "      <td>20.009</td>\n",
       "      <td>56.665</td>\n",
       "      <td>23.436</td>\n",
       "      <td>17.040</td>\n",
       "      <td>2.827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Top</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1813.529</td>\n",
       "      <td>Blade</td>\n",
       "      <td>colGrain</td>\n",
       "      <td>16.196</td>\n",
       "      <td>4.092</td>\n",
       "      <td>3.881</td>\n",
       "      <td>15.904</td>\n",
       "      <td>60.502</td>\n",
       "      <td>26.995</td>\n",
       "      <td>11.382</td>\n",
       "      <td>1.564</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Top</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PredictedHours ComponentType StructureType  CoolRate  QuenchDuration  \\\n",
       "0        1461.797        Nozzle     equiGrain    12.836           3.803   \n",
       "1        1825.977         Block   singleGrain    19.032           2.593   \n",
       "2         707.101         Blade     equiGrain    28.418           0.772   \n",
       "3        1086.370        Nozzle      colGrain     9.084           1.990   \n",
       "4        1813.529         Blade      colGrain    16.196           4.092   \n",
       "\n",
       "   ForgeDuration  HeatProcessTime  NickelComposition  IronComposition  \\\n",
       "0          6.515           47.005             65.450           16.618   \n",
       "1          3.521           45.246             54.162           34.916   \n",
       "2          1.327            9.639             52.565           36.486   \n",
       "3          2.201           20.009             56.665           23.436   \n",
       "4          3.881           15.904             60.502           26.995   \n",
       "\n",
       "   CobaltComposition  ChromiumComposition  MinorDefects  MajorDefects  \\\n",
       "0             16.510                0.938            10             0   \n",
       "1              6.063                4.292            19             0   \n",
       "2              8.927                3.355            35             3   \n",
       "3             17.040                2.827             0             1   \n",
       "4             11.382                1.564            10             0   \n",
       "\n",
       "   EdgeDefects InitialPosition FormationMethod  \n",
       "0            0          Bottom             Die  \n",
       "1            0          Bottom      Investment  \n",
       "2            0          Bottom      Investment  \n",
       "3            0             Top      Continuous  \n",
       "4            0             Top             Die  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: View the first 5 rows of your dataframe\n",
    "#\n",
    "# Hint: Use .head()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictedHours</th>\n",
       "      <th>ComponentType</th>\n",
       "      <th>StructureType</th>\n",
       "      <th>CoolRate</th>\n",
       "      <th>QuenchDuration</th>\n",
       "      <th>ForgeDuration</th>\n",
       "      <th>HeatProcessTime</th>\n",
       "      <th>NickelComposition</th>\n",
       "      <th>IronComposition</th>\n",
       "      <th>CobaltComposition</th>\n",
       "      <th>ChromiumComposition</th>\n",
       "      <th>MinorDefects</th>\n",
       "      <th>MajorDefects</th>\n",
       "      <th>EdgeDefects</th>\n",
       "      <th>InitialPosition</th>\n",
       "      <th>FormationMethod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1197.610</td>\n",
       "      <td>Block</td>\n",
       "      <td>singleGrain</td>\n",
       "      <td>5.031</td>\n",
       "      <td>1.938</td>\n",
       "      <td>8.530</td>\n",
       "      <td>35.313</td>\n",
       "      <td>68.612</td>\n",
       "      <td>20.796</td>\n",
       "      <td>7.085</td>\n",
       "      <td>4.012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>754.437</td>\n",
       "      <td>Block</td>\n",
       "      <td>singleGrain</td>\n",
       "      <td>10.183</td>\n",
       "      <td>0.661</td>\n",
       "      <td>7.937</td>\n",
       "      <td>45.506</td>\n",
       "      <td>51.257</td>\n",
       "      <td>32.335</td>\n",
       "      <td>12.088</td>\n",
       "      <td>4.341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1427.221</td>\n",
       "      <td>Nozzle</td>\n",
       "      <td>equiGrain</td>\n",
       "      <td>16.707</td>\n",
       "      <td>3.096</td>\n",
       "      <td>7.578</td>\n",
       "      <td>59.458</td>\n",
       "      <td>54.664</td>\n",
       "      <td>33.747</td>\n",
       "      <td>9.293</td>\n",
       "      <td>3.465</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1118.894</td>\n",
       "      <td>Valve</td>\n",
       "      <td>colGrain</td>\n",
       "      <td>22.592</td>\n",
       "      <td>4.442</td>\n",
       "      <td>2.393</td>\n",
       "      <td>17.944</td>\n",
       "      <td>50.290</td>\n",
       "      <td>31.723</td>\n",
       "      <td>13.223</td>\n",
       "      <td>4.676</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Top</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1084.473</td>\n",
       "      <td>Valve</td>\n",
       "      <td>colGrain</td>\n",
       "      <td>9.913</td>\n",
       "      <td>3.572</td>\n",
       "      <td>2.259</td>\n",
       "      <td>40.256</td>\n",
       "      <td>65.814</td>\n",
       "      <td>12.139</td>\n",
       "      <td>17.607</td>\n",
       "      <td>3.337</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Top</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PredictedHours ComponentType StructureType  CoolRate  QuenchDuration  \\\n",
       "995        1197.610         Block   singleGrain     5.031           1.938   \n",
       "996         754.437         Block   singleGrain    10.183           0.661   \n",
       "997        1427.221        Nozzle     equiGrain    16.707           3.096   \n",
       "998        1118.894         Valve      colGrain    22.592           4.442   \n",
       "999        1084.473         Valve      colGrain     9.913           3.572   \n",
       "\n",
       "     ForgeDuration  HeatProcessTime  NickelComposition  IronComposition  \\\n",
       "995          8.530           35.313             68.612           20.796   \n",
       "996          7.937           45.506             51.257           32.335   \n",
       "997          7.578           59.458             54.664           33.747   \n",
       "998          2.393           17.944             50.290           31.723   \n",
       "999          2.259           40.256             65.814           12.139   \n",
       "\n",
       "     CobaltComposition  ChromiumComposition  MinorDefects  MajorDefects  \\\n",
       "995              7.085                4.012             0             0   \n",
       "996             12.088                4.341             1             0   \n",
       "997              9.293                3.465            16             1   \n",
       "998             13.223                4.676            11             0   \n",
       "999             17.607                3.337             9             3   \n",
       "\n",
       "     EdgeDefects InitialPosition FormationMethod  \n",
       "995            0          Bottom      Investment  \n",
       "996            0          Bottom      Investment  \n",
       "997            0          Bottom      Investment  \n",
       "998            0             Top      Continuous  \n",
       "999            0             Top      Continuous  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: View the last 5 rows of your dataframe\n",
    "#\n",
    "# Hint: Use .tail()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Types and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   PredictedHours       1000 non-null   float64\n",
      " 1   ComponentType        1000 non-null   object \n",
      " 2   StructureType        1000 non-null   object \n",
      " 3   CoolRate             1000 non-null   float64\n",
      " 4   QuenchDuration       1000 non-null   float64\n",
      " 5   ForgeDuration        1000 non-null   float64\n",
      " 6   HeatProcessTime      1000 non-null   float64\n",
      " 7   NickelComposition    1000 non-null   float64\n",
      " 8   IronComposition      1000 non-null   float64\n",
      " 9   CobaltComposition    1000 non-null   float64\n",
      " 10  ChromiumComposition  1000 non-null   float64\n",
      " 11  MinorDefects         1000 non-null   int64  \n",
      " 12  MajorDefects         1000 non-null   int64  \n",
      " 13  EdgeDefects          1000 non-null   int64  \n",
      " 14  InitialPosition      1000 non-null   object \n",
      " 15  FormationMethod      1000 non-null   object \n",
      "dtypes: float64(9), int64(3), object(4)\n",
      "memory usage: 125.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display info about your dataframe (data types, non-null counts)\n",
    "#\n",
    "# Hint: Use .info()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictedHours</th>\n",
       "      <th>CoolRate</th>\n",
       "      <th>QuenchDuration</th>\n",
       "      <th>ForgeDuration</th>\n",
       "      <th>HeatProcessTime</th>\n",
       "      <th>NickelComposition</th>\n",
       "      <th>IronComposition</th>\n",
       "      <th>CobaltComposition</th>\n",
       "      <th>ChromiumComposition</th>\n",
       "      <th>MinorDefects</th>\n",
       "      <th>MajorDefects</th>\n",
       "      <th>EdgeDefects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1298.230182</td>\n",
       "      <td>17.641305</td>\n",
       "      <td>2.764455</td>\n",
       "      <td>5.462845</td>\n",
       "      <td>30.190170</td>\n",
       "      <td>60.238923</td>\n",
       "      <td>24.544107</td>\n",
       "      <td>12.425300</td>\n",
       "      <td>2.767316</td>\n",
       "      <td>17.311000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>340.891313</td>\n",
       "      <td>7.497384</td>\n",
       "      <td>1.317810</td>\n",
       "      <td>2.604252</td>\n",
       "      <td>16.885729</td>\n",
       "      <td>5.831078</td>\n",
       "      <td>7.366605</td>\n",
       "      <td>4.331882</td>\n",
       "      <td>1.327204</td>\n",
       "      <td>12.268365</td>\n",
       "      <td>1.163982</td>\n",
       "      <td>1.199239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>420.800000</td>\n",
       "      <td>4.918000</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.016000</td>\n",
       "      <td>1.024000</td>\n",
       "      <td>49.034000</td>\n",
       "      <td>6.724000</td>\n",
       "      <td>4.938000</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1040.893250</td>\n",
       "      <td>11.120750</td>\n",
       "      <td>1.641000</td>\n",
       "      <td>3.172250</td>\n",
       "      <td>16.217500</td>\n",
       "      <td>55.189000</td>\n",
       "      <td>19.317750</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.593750</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1267.747500</td>\n",
       "      <td>17.762500</td>\n",
       "      <td>2.752000</td>\n",
       "      <td>5.479500</td>\n",
       "      <td>29.422500</td>\n",
       "      <td>60.502500</td>\n",
       "      <td>24.616500</td>\n",
       "      <td>12.528500</td>\n",
       "      <td>2.862500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1561.212750</td>\n",
       "      <td>24.350250</td>\n",
       "      <td>3.956750</td>\n",
       "      <td>7.738750</td>\n",
       "      <td>45.109500</td>\n",
       "      <td>65.140750</td>\n",
       "      <td>29.881000</td>\n",
       "      <td>16.046500</td>\n",
       "      <td>3.925000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2155.117000</td>\n",
       "      <td>30.585000</td>\n",
       "      <td>5.079000</td>\n",
       "      <td>10.089000</td>\n",
       "      <td>60.071000</td>\n",
       "      <td>71.106000</td>\n",
       "      <td>43.636000</td>\n",
       "      <td>20.265000</td>\n",
       "      <td>5.086000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PredictedHours     CoolRate  QuenchDuration  ForgeDuration  \\\n",
       "count     1000.000000  1000.000000     1000.000000    1000.000000   \n",
       "mean      1298.230182    17.641305        2.764455       5.462845   \n",
       "std        340.891313     7.497384        1.317810       2.604252   \n",
       "min        420.800000     4.918000        0.492000       1.016000   \n",
       "25%       1040.893250    11.120750        1.641000       3.172250   \n",
       "50%       1267.747500    17.762500        2.752000       5.479500   \n",
       "75%       1561.212750    24.350250        3.956750       7.738750   \n",
       "max       2155.117000    30.585000        5.079000      10.089000   \n",
       "\n",
       "       HeatProcessTime  NickelComposition  IronComposition  CobaltComposition  \\\n",
       "count      1000.000000        1000.000000      1000.000000        1000.000000   \n",
       "mean         30.190170          60.238923        24.544107          12.425300   \n",
       "std          16.885729           5.831078         7.366605           4.331882   \n",
       "min           1.024000          49.034000         6.724000           4.938000   \n",
       "25%          16.217500          55.189000        19.317750           8.610000   \n",
       "50%          29.422500          60.502500        24.616500          12.528500   \n",
       "75%          45.109500          65.140750        29.881000          16.046500   \n",
       "max          60.071000          71.106000        43.636000          20.265000   \n",
       "\n",
       "       ChromiumComposition  MinorDefects  MajorDefects  EdgeDefects  \n",
       "count          1000.000000   1000.000000   1000.000000  1000.000000  \n",
       "mean              2.767316     17.311000      0.550000     0.292000  \n",
       "std               1.327204     12.268365      1.163982     1.199239  \n",
       "min               0.506000      0.000000      0.000000     0.000000  \n",
       "25%               1.593750      7.000000      0.000000     0.000000  \n",
       "50%               2.862500     18.000000      0.000000     0.000000  \n",
       "75%               3.925000     26.000000      0.000000     0.000000  \n",
       "max               5.086000     61.000000      4.000000     8.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Get summary statistics for numerical columns\n",
    "#\n",
    "# Hint: Use .describe()\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ComponentType</th>\n",
       "      <th>StructureType</th>\n",
       "      <th>InitialPosition</th>\n",
       "      <th>FormationMethod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Valve</td>\n",
       "      <td>singleGrain</td>\n",
       "      <td>Top</td>\n",
       "      <td>Die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>265</td>\n",
       "      <td>343</td>\n",
       "      <td>503</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ComponentType StructureType InitialPosition FormationMethod\n",
       "count           1000          1000            1000            1000\n",
       "unique             4             3               2               3\n",
       "top            Valve   singleGrain             Top             Die\n",
       "freq             265           343             503             366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Get summary statistics for categorical columns\n",
    "#\n",
    "# Hint: Use .describe(include='object')\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dataset Description\n",
    "\n",
    "*After looking at the data above, describe your dataset in your own words.*\n",
    "\n",
    "**Questions to answer:**\n",
    "- Where did this data come from? (Kaggle link, source)\n",
    "- What does each row represent?\n",
    "- How many features do you have?\n",
    "- What types of features do you have? (numerical, categorical)\n",
    "\n",
    "**Your description:**\n",
    "\n",
    "I chose the Kaggle dataset \"Material_Lifespan_Dataset\", where each row represents a industrial component. After initial review, I believe PredictedHours, MinorDefects, MajorDefects and EdgeDefects to be potential candidates for target variables, even though for this project I have chosen to focus on a calculated column called Defects, which will sum the 3 defect types. This leaves a total feature count of 12. Of those 12, 4 are categorical, which means we have 8 numerical features included in the dataset. \n",
    "\n",
    "The dataset can be found at https://www.kaggle.com/datasets/aounraza/material-lifespan-prediction-dataset, and below I've included the dataset description from Kaggle for easy reference.\n",
    "\n",
    "About Dataset\n",
    "This dataset contains simulated data for predicting the lifespan (in hours) of materials used in industrial components. It includes a variety of features related to material composition, manufacturing processes, and structural defects. The dataset is ideal for exploring regression techniques, feature engineering, and material sciences applications.\n",
    "\n",
    "Columns\n",
    "PredictedHours: Target variable representing the predicted lifespan (in hours).\n",
    "ComponentType: Type of component (e.g., nozzle, blade, block).\n",
    "StructureType: Microstructural grain configuration.\n",
    "CoolRate: Cooling rate during the manufacturing process.\n",
    "QuenchDuration: Duration of quenching (in seconds).\n",
    "ForgeDuration: Duration of forging (in seconds).\n",
    "HeatProcessTime: Time spent in heat treatment (in minutes).\n",
    "NickelComposition: Percentage of nickel in the material.\n",
    "IronComposition: Percentage of iron in the material.\n",
    "CobaltComposition: Percentage of cobalt in the material.\n",
    "ChromiumComposition: Percentage of chromium in the material.\n",
    "MinorDefects, MajorDefects, EdgeDefects: Defect counts of different categories.\n",
    "InitialPosition: Initial position of the component (e.g., Top, Bottom).\n",
    "FormationMethod: Casting method used in the process (e.g., Die, Continuous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Initial EDA\n",
    "\n",
    "### 3.1 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your target variable\n",
    "TARGET = 'your_target_column'  # <-- UPDATE THIS!\n",
    "\n",
    "# Basic statistics of target\n",
    "print(f\"Target Variable: {TARGET}\")\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df[TARGET].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df[TARGET].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel(TARGET)\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Distribution of {TARGET}')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df[TARGET].dropna())\n",
    "axes[1].set_ylabel(TARGET)\n",
    "axes[1].set_title(f'Box Plot of {TARGET}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check skewness\n",
    "skewness = df[TARGET].skew()\n",
    "print(f\"\\nSkewness: {skewness:.2f}\")\n",
    "if abs(skewness) > 1:\n",
    "    print(\"→ Target is highly skewed. Consider log transform in feature engineering.\")\n",
    "elif abs(skewness) > 0.5:\n",
    "    print(\"→ Target is moderately skewed.\")\n",
    "else:\n",
    "    print(\"→ Target is approximately symmetric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for duplicate rows in your dataframe\n",
    "#\n",
    "# Steps:\n",
    "# 1. Count how many duplicate rows exist using df.duplicated().sum()\n",
    "# 2. Print the count and the percentage of duplicates\n",
    "#\n",
    "# Expected output format:\n",
    "# \"Duplicate rows: X,XXX (X.XX%)\"\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a summary of missing values\n",
    "#\n",
    "# Steps:\n",
    "# 1. Calculate missing count for each column: df.isnull().sum()\n",
    "# 2. Calculate missing percentage: (df.isnull().sum() / len(df)) * 100\n",
    "# 3. Create a DataFrame with 'Missing Count' and 'Missing %' columns\n",
    "# 4. Sort by 'Missing %' descending\n",
    "# 5. Display only columns that have missing values\n",
    "#\n",
    "# Hint: You can create a DataFrame with pd.DataFrame({'col1': series1, 'col2': series2})\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values (if any)\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    missing_cols = missing_df[missing_df['Missing Count'] > 0]\n",
    "    colors = ['red' if pct > 50 else 'orange' if pct > 20 else 'steelblue' \n",
    "              for pct in missing_cols['Missing %']]\n",
    "    plt.barh(missing_cols.index, missing_cols['Missing %'], color=colors)\n",
    "    plt.xlabel('Missing Percentage')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.axvline(x=50, color='red', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Recommendation\n",
    "    high_missing = missing_cols[missing_cols['Missing %'] > 50]\n",
    "    if len(high_missing) > 0:\n",
    "        print(f\"\\n⚠️ Columns with >50% missing (consider dropping): {high_missing.index.tolist()}\")\n",
    "else:\n",
    "    print(\"✓ No missing values in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Initial Observations\n",
    "\n",
    "*Based on your initial exploration, what do you notice?*\n",
    "\n",
    "**Questions to consider:**\n",
    "- Is your target variable normally distributed or skewed?\n",
    "- Are there any obvious outliers in the target?\n",
    "- How much missing data do you have to deal with?\n",
    "- Are there any duplicate rows?\n",
    "- Any surprises or interesting findings?\n",
    "\n",
    "**Your observations:**\n",
    "\n",
    "[Write your observations here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Checkpoint 1 Submission Instructions\n",
    "\n",
    "**Congratulations!** You've completed Checkpoint 1. Before moving on, let's commit your work and submit.\n",
    "\n",
    "### Step 1: Save This Notebook\n",
    "- File → Save (or Ctrl+S / Cmd+S)\n",
    "\n",
    "### Step 2: Commit to GitHub\n",
    "Open your terminal and run these commands:\n",
    "\n",
    "```bash\n",
    "# Navigate to your project folder (if not already there)\n",
    "cd path/to/your/capstone-project\n",
    "\n",
    "# Stage your notebook and data\n",
    "git add notebooks/01_problem_statement_and_eda.ipynb\n",
    "git add data/raw/\n",
    "\n",
    "# Commit with a meaningful message\n",
    "git commit -m \"Complete Checkpoint 1: Problem statement and initial EDA\"\n",
    "\n",
    "# Push to GitHub\n",
    "git push\n",
    "```\n",
    "\n",
    "### Step 3: Submit to Canvas\n",
    "1. Go to the Checkpoint 1 assignment on Canvas\n",
    "2. Submit the link to your GitHub repository\n",
    "3. Make sure your repo shows your latest commit!\n",
    "\n",
    "### Step 4: Continue to Checkpoint 2\n",
    "Now proceed to **Section 4** below to continue with your complete EDA, data cleaning, and feature engineering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CHECKPOINT 2 (Due: Feb 8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Complete EDA\n",
    "\n",
    "### 4.1 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a list of numerical columns (excluding the target)\n",
    "#\n",
    "# Steps:\n",
    "# 1. Use df.select_dtypes(include=[np.number]) to get numerical columns\n",
    "# 2. Get the column names as a list with .columns.tolist()\n",
    "# 3. Remove TARGET from the list if it's in there\n",
    "# 4. Print the count and list of numerical features\n",
    "#\n",
    "# Store result in: numerical_cols\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 and n_cols == 1 else axes\n",
    "\n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        axes[i].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel('')\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for j in range(len(numerical_cols), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical features found (besides target).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a list of categorical columns and explore their values\n",
    "#\n",
    "# Steps:\n",
    "# 1. Use df.select_dtypes(include=['object', 'category']) to get categorical columns\n",
    "# 2. Get the column names as a list\n",
    "# 3. Print the count and list of categorical features\n",
    "# 4. For each categorical column, print:\n",
    "#    - Number of unique values: df[col].nunique()\n",
    "#    - Top 10 value counts: df[col].value_counts().head(10)\n",
    "#\n",
    "# Store result in: categorical_cols\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features (for columns with reasonable number of categories)\n",
    "cat_cols_to_plot = [col for col in categorical_cols if df[col].nunique() <= 10]\n",
    "\n",
    "if cat_cols_to_plot:\n",
    "    n_cols = 2\n",
    "    n_rows = (len(cat_cols_to_plot) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if len(cat_cols_to_plot) == 1 else axes\n",
    "    \n",
    "    for i, col in enumerate(cat_cols_to_plot):\n",
    "        df[col].value_counts().plot(kind='bar', ax=axes[i], edgecolor='black')\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for j in range(len(cat_cols_to_plot), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical columns with ≤10 unique values to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Categorical Features vs Target\n",
    "\n",
    "*How does the target variable differ across categories?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots: Target by categorical features\n",
    "cat_cols_to_analyze = [col for col in categorical_cols if df[col].nunique() <= 8]\n",
    "\n",
    "if cat_cols_to_analyze:\n",
    "    for col in cat_cols_to_analyze[:4]:  # Limit to first 4 for readability\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Order by median target value\n",
    "        order = df.groupby(col)[TARGET].median().sort_values().index\n",
    "        \n",
    "        sns.boxplot(data=df, x=col, y=TARGET, order=order)\n",
    "        plt.title(f'{TARGET} by {col}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show mean target by category\n",
    "        print(f\"\\nMean {TARGET} by {col}:\")\n",
    "        print(df.groupby(col)[TARGET].agg(['mean', 'median', 'count']).sort_values('mean', ascending=False))\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "else:\n",
    "    print(\"No suitable categorical columns for this analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and visualize a correlation matrix\n",
    "#\n",
    "# Steps:\n",
    "# 1. Create a list of columns: numerical_cols + [TARGET]\n",
    "# 2. Calculate the correlation matrix: df[columns].corr()\n",
    "# 3. Create a heatmap using sns.heatmap()\n",
    "#\n",
    "# Heatmap parameters to use:\n",
    "# - annot=True (show numbers)\n",
    "# - cmap='coolwarm' (color scheme)\n",
    "# - center=0 (center colormap at 0)\n",
    "# - fmt='.2f' (2 decimal places)\n",
    "#\n",
    "# Store the correlation matrix in: correlation_matrix\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract and analyze correlations with the target variable\n",
    "#\n",
    "# Steps:\n",
    "# 1. Get the TARGET column from correlation_matrix\n",
    "# 2. Drop the TARGET's correlation with itself (it's always 1.0)\n",
    "# 3. Sort values in descending order\n",
    "# 4. Print the correlations\n",
    "# 5. Identify strong correlations (absolute value > 0.5)\n",
    "#\n",
    "# Store result in: target_correlations\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations with target\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in target_correlations]\n",
    "target_correlations.plot(kind='barh', color=colors)\n",
    "plt.xlabel('Correlation')\n",
    "plt.title(f'Feature Correlations with {TARGET}')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Feature vs Target Relationships\n",
    "\n",
    "*Create scatter plots for your most promising numerical features against the target.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top correlated features to plot\n",
    "top_features = target_correlations.abs().sort_values(ascending=False).head(4).index.tolist()\n",
    "\n",
    "if len(top_features) > 0:\n",
    "    n_features = min(4, len(top_features))\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(top_features[:n_features]):\n",
    "        axes[i].scatter(df[feature], df[TARGET], alpha=0.5)\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel(TARGET)\n",
    "        corr = df[feature].corr(df[TARGET])\n",
    "        axes[i].set_title(f'{feature} vs {TARGET} (r={corr:.2f})')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(n_features, 4):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical features to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Additional Exploration (Your Choice!)\n",
    "\n",
    "The sections above provide a foundation, but every dataset is unique. Use the cells below to explore additional aspects of YOUR data that you think are important.\n",
    "\n",
    "**Ideas for additional exploration:**\n",
    "- Violin plots for categorical vs target (shows distribution shape)\n",
    "- Look at feature interactions (e.g., does the relationship between X and Y change based on Z?)\n",
    "- Explore geographic patterns (if you have location data)\n",
    "- Create pair plots for key features (`sns.pairplot()`)\n",
    "- Analyze distributions across different subgroups\n",
    "- Look for data quality issues specific to your dataset\n",
    "- Check for nonsensical values (negative prices, impossible ages, etc.)\n",
    "\n",
    "**Remember:** The best insights often come from curiosity-driven exploration, not just following a template. What questions do YOU have about your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ADDITIONAL EDA CODE HERE\n",
    "# Add as many cells as you need - don't be limited by this template!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More exploration...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What additional insights did you discover?**\n",
    "\n",
    "[Describe any additional findings from your custom exploration]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 EDA Insights Summary\n",
    "\n",
    "*Summarize your key findings from the EDA.*\n",
    "\n",
    "**Questions to answer:**\n",
    "- Which features are most correlated with your target?\n",
    "- Which categorical features show the biggest differences in target?\n",
    "- Are there any features that seem unimportant?\n",
    "- Did you discover any interesting patterns or relationships?\n",
    "- Are there any concerns about the data (outliers, skewness, etc.)?\n",
    "\n",
    "**Your summary:**\n",
    "\n",
    "[Write your summary here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Data Cleaning\n",
    "\n",
    "### 5.1 Decide What to Drop\n",
    "\n",
    "Before cleaning, decide which columns to remove entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a copy of your dataframe for cleaning\n",
    "#\n",
    "# Why? We want to preserve the original data in case we need to go back.\n",
    "# Never modify your original dataframe directly!\n",
    "#\n",
    "# Store in: df_clean\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n",
    "\n",
    "print(f\"Starting shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to potentially drop\n",
    "print(\"Columns to consider dropping:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. High missing rate\n",
    "high_missing = missing_df[missing_df['Missing %'] > 50].index.tolist()\n",
    "print(f\"\\n1. >50% missing values: {high_missing}\")\n",
    "\n",
    "# 2. ID/index columns (no predictive value)\n",
    "potential_ids = [col for col in df_clean.columns \n",
    "                 if 'id' in col.lower() or 'index' in col.lower() or 'url' in col.lower()]\n",
    "print(f\"\\n2. Potential ID/URL columns: {potential_ids}\")\n",
    "\n",
    "# 3. High cardinality categorical (too many unique values)\n",
    "high_cardinality = [col for col in categorical_cols if df_clean[col].nunique() > 100]\n",
    "print(f\"\\n3. High cardinality (>100 unique): {high_cardinality}\")\n",
    "\n",
    "# 4. Low variance (same value in most rows)\n",
    "low_variance = [col for col in df_clean.columns \n",
    "                if df_clean[col].value_counts(normalize=True).iloc[0] > 0.95]\n",
    "print(f\"\\n4. Low variance (>95% same value): {low_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "# TODO: Decide which columns to drop based on the analysis above\n",
    "# IMPORTANT: Don't just copy all suggestions - think about each one!\n",
    "\n",
    "columns_to_drop = [\n",
    "    # Add column names to drop here, e.g.:\n",
    "    # 'id',\n",
    "    # 'url',\n",
    "]\n",
    "\n",
    "if columns_to_drop:\n",
    "    df_clean = df_clean.drop(columns=columns_to_drop)\n",
    "    print(f\"Dropped {len(columns_to_drop)} columns: {columns_to_drop}\")\n",
    "    print(f\"New shape: {df_clean.shape}\")\n",
    "else:\n",
    "    print(\"No columns dropped. Update the list above if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain which columns you dropped and why:**\n",
    "\n",
    "[Describe your reasoning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Handle Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove duplicate rows from df_clean\n",
    "#\n",
    "# Steps:\n",
    "# 1. Store the row count before: len(df_clean)\n",
    "# 2. Use df_clean.drop_duplicates() to remove duplicates (assign back to df_clean)\n",
    "# 3. Store the row count after\n",
    "# 4. Print how many duplicates were removed\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in cleaned dataframe\n",
    "print(\"Missing values before handling:\")\n",
    "missing_now = df_clean.isnull().sum()\n",
    "missing_now = missing_now[missing_now > 0].sort_values(ascending=False)\n",
    "print(missing_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# TODO: Add your missing value handling code here\n",
    "# \n",
    "# STRATEGIES:\n",
    "# - Numerical columns: use median (robust to outliers) or mean\n",
    "# - Categorical columns: use mode or 'Unknown'\n",
    "# - Drop rows if missing target variable\n",
    "#\n",
    "# Examples:\n",
    "# df_clean['column'] = df_clean['column'].fillna(df_clean['column'].median())\n",
    "# df_clean['column'] = df_clean['column'].fillna('Unknown')\n",
    "# df_clean = df_clean.dropna(subset=[TARGET])  # Don't predict with missing target!\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify missing values are handled\n",
    "remaining_missing = df_clean.isnull().sum().sum()\n",
    "print(f\"Missing values after cleaning: {remaining_missing}\")\n",
    "\n",
    "if remaining_missing > 0:\n",
    "    print(\"\\n⚠️ Still have missing values in:\")\n",
    "    print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your missing value strategy:**\n",
    "\n",
    "[Describe what you did for each column and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Handle Outliers (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers using IQR method\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    n_outliers = len(data[(data[column] < lower_bound) | (data[column] > upper_bound)])\n",
    "    return n_outliers, lower_bound, upper_bound\n",
    "\n",
    "# Get current numerical columns\n",
    "current_numerical = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Outlier analysis:\")\n",
    "print(\"=\"*60)\n",
    "for col in current_numerical:\n",
    "    n_outliers, lower, upper = find_outliers_iqr(df_clean, col)\n",
    "    if n_outliers > 0:\n",
    "        pct = n_outliers / len(df_clean) * 100\n",
    "        print(f\"{col}: {n_outliers:,} outliers ({pct:.1f}%) | bounds: [{lower:.2f}, {upper:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers (if needed)\n",
    "# TODO: Add your outlier handling code here if needed\n",
    "#\n",
    "# STRATEGIES:\n",
    "# - Remove rows with outliers (be careful - losing data)\n",
    "# - Cap/clip values at bounds\n",
    "# - Keep them (if they're valid data points)\n",
    "#\n",
    "# Examples:\n",
    "# df_clean = df_clean[df_clean['price'] > 0]  # Remove invalid prices\n",
    "# df_clean = df_clean[df_clean['price'] < 500000]  # Remove extreme prices\n",
    "# df_clean['column'] = df_clean['column'].clip(lower=0, upper=upper_bound)\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your outlier handling strategy (or why you kept them):**\n",
    "\n",
    "[Describe what you did and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Data Type Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current data types\n",
    "print(\"Current data types:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix any data type issues\n",
    "# TODO: Add your data type corrections here if needed\n",
    "#\n",
    "# Examples:\n",
    "# df_clean['year'] = df_clean['year'].astype(int)\n",
    "# df_clean['date_column'] = pd.to_datetime(df_clean['date_column'])\n",
    "# df_clean['category'] = df_clean['category'].astype('category')\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Feature Engineering\n",
    "\n",
    "Feature engineering is where you can really add value! The sections below cover common techniques, but feel free to go beyond these basics.\n",
    "\n",
    "### 6.1 Create New Features (if applicable)\n",
    "\n",
    "**Common feature engineering techniques:**\n",
    "- **Ratios/interactions:** Combine existing features (e.g., price per square foot)\n",
    "- **Log transforms:** Reduce skewness in highly skewed features\n",
    "- **Binning:** Convert continuous variables to categories\n",
    "- **Text features:** Extract length, word counts, etc. from text\n",
    "- **Domain-specific:** Features that make sense for your specific problem\n",
    "\n",
    "Think about what would help YOUR specific prediction problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "# TODO: Add your feature engineering code here\n",
    "#\n",
    "# Examples:\n",
    "# df_clean['price_per_sqft'] = df_clean['price'] / df_clean['sqft']\n",
    "# df_clean['log_price'] = np.log1p(df_clean['price'])\n",
    "# df_clean['age'] = 2026 - df_clean['year']\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your new features:**\n",
    "\n",
    "[Describe what features you created and why they might help predict the target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify categorical columns that need encoding\n",
    "#\n",
    "# Steps:\n",
    "# 1. Get categorical columns using select_dtypes(include=['object', 'category'])\n",
    "# 2. For each column, print:\n",
    "#    - Column name\n",
    "#    - Number of unique values: .nunique()\n",
    "#    - Recommendation: \"one-hot encoding\" if <= 10 unique, else \"consider label encoding or dropping\"\n",
    "#\n",
    "# Store in: cat_cols\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "# TODO: Add your encoding code here\n",
    "#\n",
    "# STRATEGIES:\n",
    "# - One-hot encoding: for low cardinality (< 10 unique values)\n",
    "# - Label encoding: for ordinal data or high cardinality\n",
    "# - Target encoding: advanced technique (be careful of data leakage)\n",
    "#\n",
    "# Examples:\n",
    "# One-hot encoding:\n",
    "# df_clean = pd.get_dummies(df_clean, columns=['category_col'], drop_first=True)\n",
    "#\n",
    "# Label encoding:\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# df_clean['encoded_col'] = le.fit_transform(df_clean['category_col'])\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your encoding strategy:**\n",
    "\n",
    "[Describe what encoding methods you used and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Additional Feature Engineering (Your Choice!)\n",
    "\n",
    "Every dataset has unique opportunities for feature engineering. What else makes sense for YOUR data?\n",
    "\n",
    "**Think about:**\n",
    "- What domain knowledge can you apply?\n",
    "- Are there any feature interactions that might be predictive?\n",
    "- Can you create meaningful groups or categories?\n",
    "- Would polynomial features help capture non-linear relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ADDITIONAL FEATURE ENGINEERING CODE HERE\n",
    "# Add as many cells as you need!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain your additional feature engineering:**\n",
    "\n",
    "[Describe any additional features you created and your reasoning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Feature Scaling (Preparation)\n",
    "\n",
    "We'll do actual scaling in the modeling notebook, but let's check which features might need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Identify numerical features and check their ranges\n",
    "#\n",
    "# Steps:\n",
    "# 1. Get numerical columns from df_clean (excluding TARGET)\n",
    "# 2. For each column, print the min, max, and range\n",
    "#\n",
    "# This helps you understand if features need scaling (different scales = need scaling)\n",
    "#\n",
    "# Store in: numerical_features\n",
    "\n",
    "# YOUR CODE HERE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Final Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data quality checks before saving\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL DATA QUALITY CHECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. Shape: {df_clean.shape[0]:,} rows, {df_clean.shape[1]} columns\")\n",
    "print(f\"   (Started with {df.shape[0]:,} rows, {df.shape[1]} columns)\")\n",
    "\n",
    "print(f\"\\n2. Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n3. Duplicate rows: {df_clean.duplicated().sum()}\")\n",
    "\n",
    "print(f\"\\n4. Target variable '{TARGET}':\")\n",
    "print(f\"   - Min: {df_clean[TARGET].min():.2f}\")\n",
    "print(f\"   - Max: {df_clean[TARGET].max():.2f}\")\n",
    "print(f\"   - Mean: {df_clean[TARGET].mean():.2f}\")\n",
    "\n",
    "# Check for data leakage red flags\n",
    "print(f\"\\n5. Data types:\")\n",
    "print(f\"   - Numerical: {len(df_clean.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"   - Categorical: {len(df_clean.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "\n",
    "remaining_cats = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if remaining_cats:\n",
    "    print(f\"\\n⚠️ Still have categorical columns: {remaining_cats}\")\n",
    "    print(\"   Make sure these are encoded before modeling!\")\n",
    "else:\n",
    "    print(\"\\n✓ All features are numerical. Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check of cleaned data\n",
    "print(\"Final cleaned dataset:\")\n",
    "print(f\"Shape: {df_clean.shape}\")\n",
    "print(f\"\\nColumns ({len(df_clean.columns)}):\")\n",
    "print(df_clean.columns.tolist())\n",
    "print(f\"\\nData types:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df_clean.to_csv('../data/processed/cleaned_data.csv', index=False)\n",
    "print(\"✓ Cleaned data saved to ../data/processed/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Feature Engineering Summary\n",
    "\n",
    "*Summarize all the data cleaning and feature engineering you performed.*\n",
    "\n",
    "**Checklist:**\n",
    "- [ ] Columns dropped (with justification)\n",
    "- [ ] Duplicate rows removed\n",
    "- [ ] Missing values handled\n",
    "- [ ] Outliers addressed (or documented why not)\n",
    "- [ ] Data types corrected\n",
    "- [ ] New features created (if applicable)\n",
    "- [ ] Categorical variables encoded\n",
    "- [ ] Data saved to processed folder\n",
    "\n",
    "**Summary of changes:**\n",
    "\n",
    "[Write a thorough summary of everything you did to clean and transform the data]\n",
    "\n",
    "**Final feature list for modeling:**\n",
    "\n",
    "[List all the features you'll use in your models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Checkpoint 2 Submission Instructions\n",
    "\n",
    "**Congratulations!** You've completed Checkpoint 2 (EDA, Data Cleaning, and Feature Engineering).\n",
    "\n",
    "### Step 1: Save This Notebook\n",
    "- File → Save (or Ctrl+S / Cmd+S)\n",
    "\n",
    "### Step 2: Commit to GitHub\n",
    "\n",
    "```bash\n",
    "# Stage your changes\n",
    "git add notebooks/01_problem_statement_and_eda.ipynb\n",
    "git add data/processed/\n",
    "\n",
    "# Commit with a meaningful message\n",
    "git commit -m \"Complete Checkpoint 2: EDA, data cleaning, and feature engineering\"\n",
    "\n",
    "# Push to GitHub\n",
    "git push\n",
    "```\n",
    "\n",
    "### Step 3: Submit to Canvas\n",
    "1. Go to the Checkpoint 2 assignment on Canvas\n",
    "2. Submit the link to your GitHub repository\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "You're ready to move on to **Notebook 02: Regression Model**!\n",
    "\n",
    "In that notebook, you'll:\n",
    "1. Load your cleaned data\n",
    "2. Split into train/test sets\n",
    "3. Build and evaluate regression models\n",
    "4. Save your best model\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
